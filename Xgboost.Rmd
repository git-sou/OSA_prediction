---
title: "R Notebook"
output: html_notebook
---


```{r}
rm(list=ls())
list=ls()
```

```{r, echo=FALSE}
library(dplyr)
library(readxl)
library(caret)
library(xgboost)
```

DATA IMPORTATION:
```{r}
Data_Directory <- "~/Desktop/OSA Case/Regression Notebook/"

setwd(Data_Directory)

train_file <- "train.xlsx"
test_file <- "test.xlsx"

train <- read_excel(paste(Data_Directory, train_file, sep = ""))
test <- read_excel(paste(Data_Directory, test_file, sep = ""))
```

LEARNING PROCESS:
tuning eta
```{r}
set.seed(1)
train_Control <- trainControl(method="cv", number=10)

tune_grid1 <- expand.grid(nrounds = seq(from = 50, to = 1000, by = 50),
  eta = c(0.025, 0.05, 0.1, 0.3), max_depth = c(2,3,4),
  gamma = 0, colsample_bytree = 1,
  min_child_weight = 1, subsample = 1)

model1 <- train(IAH ~ Age+Cervical+BMI, data =train,
               method="xgbTree",trControl=train_Control, 
               tuneGrid = tune_grid1)

print(model1)

print(model1$finalModel)
```

tuning of maximum depth and minimum child weight
```{r}
set.seed(1)
tune_grid2 <- expand.grid(nrounds = seq(from = 50, to = 1000, by = 50),
  eta = model1$bestTune$eta, max_depth = c(2, 3, 4, 5, 6),
  gamma = 0, colsample_bytree = 1,
  min_child_weight = c(1,2,3), subsample = 1)

model2 <- train(IAH ~ Age+Cervical+BMI, data =train,
               method="xgbTree",trControl=train_Control, 
               tuneGrid = tune_grid2)

print(model2)

print(model2$finalModel)
```

tuning colsample and subsample
```{r}
set.seed(1)
tune_grid3 <- expand.grid(nrounds = seq(from = 50, to = 1000, by = 50),
  eta = model1$bestTune$eta, max_depth = model2$bestTune$max_depth,
  gamma = 0, colsample_bytree = 1,
  min_child_weight = model2$bestTune$min_child_weight, subsample = c(0.5, 0.75, 1.0))

model3 <- train(IAH ~ Age+Cervical+BMI, data =train,
               method="xgbTree",trControl=train_Control, 
               tuneGrid = tune_grid3)

print(model3)

print(model3$finalModel)
```

tuning eta again
```{r}
tune_grid <- expand.grid(nrounds = seq(from = 50, to = 1000, by = 50),
  eta = c(0.01, 0.015, 0.025), max_depth = model2$bestTune$max_depth,
  gamma = 0, colsample_bytree = model3$bestTune$colsample_bytree,
  min_child_weight = model2$bestTune$min_child_weight, subsample = model3$bestTune$subsample)

xgboost <- train(IAH ~ Age+Cervical+BMI, data =train,
               method="xgbTree",trControl=train_Control, 
               tuneGrid = tune_grid)

print(xgboost)
```

```{r}
plot(model1, xlab = "Iterations")
plot(model2, xlab = "Iterations")
plot(model3, xlab = "Iterations")
plot(xgboost, xlab = "Iterations")
```
PREDICTION PROCESS:
```{r}
pred <- predict(xgboost,newdata=test)
```


```{r}
metrics = postResample(pred, test$IAH)
metrics
```


```{r}
my_data = as.data.frame(cbind(predicted = pred, observed = test$IAH))

# Plot predictions vs test data
ggplot(my_data,aes(predicted, observed)) + geom_point(color = "darkred", alpha = 0.5) + 
    geom_smooth(method=lm)+ ggtitle('Linear Regression ') + ggtitle("Extreme Gradient Boosting: Prediction vs Test Data") +
      xlab("Predecited Power Output ") + ylab("Observed Power Output") + 
        theme(plot.title = element_text(color="darkgreen",size=16,hjust = 0.5),
         axis.text.y = element_text(size=12), axis.text.x = element_text(size=12,hjust=.5),
         axis.title.x = element_text(size=14), axis.title.y = element_text(size=14))
```


```{r}
plot(abs(test$IAH-pred),xlab="IAH",type='p',col='blue')
```

EXPORT OF DATA:
- import the excel file
```{r, setup, include=FALSE}
Data_Directory <- "~/Desktop/OSA Case/Results/"

knitr::opts_knit$set(root.dir = Data_Directory)

file <- "Regression Results.xlsx"

results <- read_excel(paste(Data_Directory, file, sep = ""))
```

- write into it:
```{r}
results$XgBoost = metrics
write_xlsx(results, paste(Data_Directory, file, sep = ""))
```
